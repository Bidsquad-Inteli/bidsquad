{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsHKbbzPRZuD"
      },
      "outputs": [],
      "source": [
        "# labels / y\n",
        "ratings = [\n",
        "    4, 1, 8, 1, 7, 9, 10, 18, 4, 3, 13, 3, 7, 10, 3, 4, 7, 5, 6, 12,\n",
        "    16, 10, 5, 10, 20, 16, 19, 19, 5, 0, 2, 3, 4, 7, 5, 2, 8, 7, 5, 5,\n",
        "    5, 11, 0, 3, 1, 3, 6, 4, 1, 1, 5, 5, 3, 6, 11, 6, 6, 8, 1, 10,\n",
        "    3, 5, 10, 0, 1, 0, 0, 3, 5, 3, 12, 3, 1, 1, 2, 6, 2, 0, 0, 6,\n",
        "    6, 3, 3, 4, 7, 8, 6, 0, 0, 6, 6, 13, 0, 14, 1, 5, 0, 0, 0, 0,\n",
        "    0, 0, 4, 4, 9, 6, 6, 0, 2, 6, 2, 7, 6, 0, 1, 0, 6, 5, 3, 3,\n",
        "    18, 17, 10, 10, 10, 11, 19, 17, 19, 7, 4, 19, 13, 6, 5, 5, 2, 1,\n",
        "    0, 0, 3, 3, 1, 7, 7, 7, 3, 8, 5, 4, 6, 5, 3, 5, 8, 5, 6, 11,\n",
        "    0, 0, 4, 10, 13, 9, 12, 16, 12, 5, 3, 2, 1, 3, 3, 1, 4, 4, 17, 17,\n",
        "    19, 14, 15, 13, 10, 9, 17, 19, 11, 17, 9\n",
        "]\n",
        "\n",
        "# images / X\n",
        "training_images = []\n",
        "for i in range(0,189):\n",
        "  training_images.append(str(i)+\".png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzL-4twlSoKA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "X = []\n",
        "for file_name in training_images:\n",
        "    img = cv2.imread(f\"data/{file_name}\")\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    X.append(img)\n",
        "\n",
        "X = np.array(X) / 255\n",
        "y = np.array(ratings)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2\n",
        ")\n",
        "\n",
        "augment_factor = 4\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "for x, y in zip(X_train, y_train):\n",
        "    augmented_images.append(x)\n",
        "    augmented_labels.append(y)\n",
        "    for _ in range(augment_factor - 1):\n",
        "        transformed_image = datagen.random_transform(x)\n",
        "        augmented_images.append(transformed_image)\n",
        "        augmented_labels.append(y)\n",
        "\n",
        "augmented_X_train = np.array(augmented_images)\n",
        "augmented_y_train = np.array(augmented_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rXEfdNXSu8n"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3,3), activation='relu', input_shape=(256,256, 3)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(128, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Conv2D(256, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "        ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=12, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXKUAAqAT1o-",
        "outputId": "44098690-a57c-48c5-e449-378af715b21d"
      },
      "outputs": [],
      "source": [
        "model.fit(augmented_X_train, augmented_y_train, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Benchmarking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUzVbVFNaajy",
        "outputId": "b01e30ed-d88e-4733-ab9d-a23a2151cf25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 37ms/step - loss: 1.2789\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.278922200202942"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exporting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import lite\n",
        "\n",
        "converter = lite.TFLiteConverter.from_keras_model(model)\n",
        "tfmodel = converter.convert()\n",
        "\n",
        "open(\"model.tflite\" , \"wb\").write(tfmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing & using our model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "loaded_model = joblib.load('model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCHL6JtOaHP7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread(\"yourImage\")\n",
        "img = cv2.resize(img, (256, 256))\n",
        "img = np.array(img) / 255\n",
        "img = np.expand_dims(img, axis=0)\n",
        "results = round(float(model.predict(img)[0][0]), 1)\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
